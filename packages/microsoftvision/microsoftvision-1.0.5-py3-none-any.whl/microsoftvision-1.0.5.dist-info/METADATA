Metadata-Version: 2.1
Name: microsoftvision
Version: 1.0.5
Summary: Downloads pretrained Microsoft Vision models
Home-page: UNKNOWN
License: UNKNOWN
Platform: UNKNOWN
Description-Content-Type: text/markdown
Requires-Dist: torch (>=1.2.0)
Requires-Dist: azure-storage-blob
Requires-Dist: azure-identity
Requires-Dist: tqdm

# Microsoft Vision

## Installation
``pip install microsoftvision``


## Usage
Input images should be in <b>BGR</b> format of shape (3 x H x W), where H and W are expected to be at least 224.
The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].

Example script:  
```
import microsoftvision
import torch

# This will load pretrained model
model = microsoftvision.models.resnet50(pretrained=True)

# Load model to CPU memory, interface is the same as torchvision
model = microsoftvision.models.resnet50(pretrained=True, map_location=torch.device('cpu')) 
```

Example of creating image embeddings:
```
import microsoftvision
from torchvision import transforms
import torch
from PIL import Image

def get_image():
    img = cv2.imread('example.jpg', cv2.IMREAD_COLOR)
    img = cv2.resize(img, (256, 256))
    img = img[16:256-16, 16:256-16]
    preprocess = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return preprocess(image).unsqueeze(0) # Unsqueeze only required when there's 1 image in images batch

model = microsoftvision.models.resnet50(pretrained=True)
features = model(get_image())
print(features.shape)
```
Should output
```
...
torch.Size([1, 2048])
```


