Metadata-Version: 2.1
Name: parallelworkloads
Version: 0.1.2
Summary: A Python Wrapper for the workload model proposed by Lublin
Home-page: https://github.com/renatolfc/parallelworkloads
Author: Renato L. de F. Cunha
Author-email: renatocunha@acm.org
License: UNKNOWN
Project-URL: Bug Reports, https://github.com/renatolfc/parallelworkloads/issues
Project-URL: Say Thanks!, https://saythanks.io/to/renatocunha%40acm.org
Project-URL: Source, https://github.com/renatolfc/parallelworkloads
Keywords: workload,standard workload format,swf
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3 :: Only
Requires-Python: >=3.6, <4
Description-Content-Type: text/x-rst
Provides-Extra: dev
Requires-Dist: cython ; extra == 'dev'

lublinworkload
==============

A Python port of the Workload Model proposed by Lublin & Feitelson.

The following code shows how to use it:

.. code:: python

   from parallelworkloads import lublin99
   w = lublin99.Lublin99(1, 2)  # Will use both batch and interactive jobs
   w.numJobs=4  # will generate four jobs
   w.generate()  # The four generated jobs are shown below

   [SwfJob(jobId=1, submissionTime=103, waitTime=-1, runTime=12379,
   allocProcs=16, avgCpuUsage=-1, usedMem=-1, reqProcs=-1, reqTime=-1,
   reqMem=-1, status=1, userId=-1, groupId=-1, executable=-1, queueNum=1,
   partNum=-1, precedingJob=-1, thinkTime=-1),

   SwfJob(jobId=2, submissionTime=3089, waitTime=-1, runTime=177,
   allocProcs=16, avgCpuUsage=-1, usedMem=-1, reqProcs=-1, reqTime=-1,
   reqMem=-1, status=1, userId=-1, groupId=-1, executable=-1, queueNum=1,
   partNum=-1, precedingJob=-1, thinkTime=-1),

   SwfJob(jobId=3, submissionTime=3150, waitTime=-1, runTime=10, allocProcs=2,
   avgCpuUsage=-1, usedMem=-1, reqProcs=-1, reqTime=-1, reqMem=-1, status=1,
   userId=-1, groupId=-1, executable=-1, queueNum=0, partNum=-1,
   precedingJob=-1, thinkTime=-1),

   SwfJob(jobId=4, submissionTime=3172, waitTime=-1, runTime=7,
   allocProcs=32, avgCpuUsage=-1, usedMem=-1, reqProcs=-1, reqTime=-1,
   reqMem=-1, status=1, userId=-1, groupId=-1, executable=-1, queueNum=0,
   partNum=-1, precedingJob=-1, thinkTime=-1)]

User runtime estimates
----------------------

`parallelworkloads` also supports generating runtime estimates based on the
model proposed by Dan Tsafrir in 2005. For the model to work, it needs at least
200 jobs. Here's an example continuing the previous one:

.. code:: python

   from parallelworkloads import tsafrir05

   w.numJobs = 200
   jobs = w.generate()
   print('Original requested time of first job:', jobs[0].reqTime)
   t = tsafrir05.Tsafrir05(jobs)
   jobs = t.generate(jobs)
   print('Generated requested time of first job:', jobs[0].reqTime)

Which gives as output:

.. code::

   Original requested time: -1
   Generated requested time: 22962.0


