# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['azulejo', 'azulejo.installer_data.dagchainer-tool']

package_data = \
{'': ['*'],
 'azulejo': ['examples/glycine7/*',
             'installer_data/blast-longids/*',
             'installer_data/blast-longids/linux/*',
             'installer_data/blast-longids/macos/*',
             'installer_data/mmseqs/linux/*',
             'installer_data/mmseqs/macos/*',
             'installer_data/muscle/*',
             'installer_data/muscle/linux/*',
             'installer_data/muscle/macos/*',
             'installer_data/usearch/*',
             'installer_data/usearch/linux/*',
             'installer_data/usearch/macos/*']}

install_requires = \
['amas>=1.0,<2.0',
 'attrs',
 'beautifulsoup4>=4.9.3,<5.0.0',
 'biopython>=1.78,<2.0',
 'click>=7.1.2,<8.0.0',
 'click_loguru>=1.3.0,<2.0.0',
 'click_plugins>=1.1.1,<2.0.0',
 'dask[bag]>=2.15.0,<3.0.0',
 'fastaq>=0.30,<0.31',
 'gffpandas-jb>=1.2.1.1,<2.0.0.0',
 'matplotlib>=3.2.1,<4.0.0',
 'memory-tempfile>=2.2.3,<3.0.0',
 'networkx>=2.4,<3.0',
 'numpy>=1.18.3,<2.0.0',
 'packaging>=20.7,<21.0',
 'pandas>=1.1.0,<2.0.0',
 'paramiko>=2.7.1,<3.0.0',
 'pathvalidate>=2.3.0,<3.0.0',
 'phylopandas>=0.8.0,<0.9.0',
 'progressbar2>=3.53.1,<4.0.0',
 'pyarrow>=2.0.0,<3.0.0',
 'requests_download>=0.1.2,<0.2.0',
 'seaborn>=0.11.0,<0.12.0',
 'sh>=1.14.1,<2.0.0',
 'smart-open>=2.0.0,<3.0.0',
 'toml>=0.10.1,<0.11.0',
 'uri>=2.0.1,<3.0.0',
 'xxhash>=2.0.0,<3.0.0']

entry_points = \
{'console_scripts': ['azulejo = azulejo:cli']}

setup_kwargs = {
    'name': 'azulejo',
    'version': '0.10.1',
    'description': 'tile phylogenetic space with subtrees',
    'long_description': '.. epigraph:: azulejo\n              noun INFORMAL\n              a glazed tile, usually blue, found on the inside of churches and palaces in Spain and Portugal.\n\nazulejo\n=======\n``azulejo`` azulejo combines homology and synteny information to\ntile phylogenetic space.\nThe inputs to ``azulejo`` are FASTA files of nucleotide-space\nsequences of primary-transcript protein genes and their associated GFF files.\nOutputs are sets of proxy gene fragments chosen for \ntheir concordance in multiple sequence alignments, along with\nsubtrees.\n\nPrerequisites\n-------------\nPython 3.7 or greater is required. ``azulejo`` is tested under Linux \nusing Python 3.8 and 3.9 and under MacOS Big Sur using XCode command-line tools\nsystem Python (currently 3.8). Mac users should see the `instructions\non configuring their systems <macos.rst>`_.  Installation on BSD is not\nsupported because many of the python dependencies lack BSD wheels.\n\nWe recommend you install ``azulejo`` into its own virtual environment due\nto the large number of python dependencies.  The easiest way for most \nusers to install and maintain up-to-date virtual environments is via the\ntool `pipx <https://pipxproject.github.io/pipx>`_.  If your system does\nnot have ``pipx`` installed, you can do so via the commands::\n\n        python3 -m pip install --user --upgrade pip\n        python3 -m pip install --user --upgrade pipx\n        python3 -m pipx ensurepath\n\nFollow any instructions that the last command produces about starting a new\nshell if necessary.  \n\nIf you choose to have ``azulejo`` compile and install its binary dependencies,\nyou will need compilers, ``make``, and ``cmake``  and standard headers\nfor ``zlib`` and ``bz2``.  All linux systems configured for development will have\nthese available.  We test compilation under gcc version 10.2 on linux and\nclang 12.0.0 on MacOS.  We use program-guided optimization for one of the\nbinary dependencies, and we believe that gcc 10 does a much better job\nof optimization than gcc 9, so it may benefit you to upgrade your compiler\nif needed.\n\nInstallation for Users\n----------------------\nOnce the prerequisite has been met, you may then install ``azulejo`` \nin its own virtual environment by issuing the command::\n\n        pipx install azulejo\n\n``azulejo`` contains some long commands and many options.  To enable command-line\ncompletion for ``azulejo`` commands, execute the following command if you are using\n``bash`` as your shell: ::\n\n    eval "$(_AZULEJO_COMPLETE=source_bash azulejo)"\n\nIf you are using ``zsh``, simply replace ``source_bash`` in the above command line\nwith ``source_zsh``.\n\nYou may next proceed with installing binary dependencies.\n\nEnvironmental Variables\n-----------------------\n``azulejo`` recognizes the following environmental variables:\n\nAZULEJO_INSTALL_DIR\n  This is a writable directory for installation of binary dependencies.  Binaries\n  will go into the ``bin`` directory.  The default is the virtual environment\n  directory.\n\nBUILD_DEV\n  This is the directory used for building binary dependencies.  Default is the\n  first memory device found for linux (e.g., `/run/shm`) or `/tmp` for MacOS.\n  Set this if compilation fails because it runs out of memory.\n\nSCRATCH_DEV\n  This is the directory used for temporary merging of lists.  The default is\n  `/tmp`, but you may set it to a fast memory based device if you have enough\n  memory.\n\nMAKEOPTS\n  These are the arguments to the ``make`` and ``make install`` commands when\n  building dependencies.  It\'s good to set this to the number of processors\n  on your system before installing required dependencies.  This variable is\n  only used during ``azulejo install``.\n\nSPINNER_UPDATE_PERIOD\n  This is the number of seconds between updates of the spinner.  This\n  defaults to 1, but it is advisable to set it higher for automated testing\n  so as not to exceed logfile character limits.\n\nLOG_TO_PRINT\n  If set to a log level such as ``info``, the logger will be a simple print \n  without using the more\n  complex functions of ``loguru`` such as colors and logging to files.\n  This is sometimes useful in automated testing.\n\nIn addition the optional ``dagchainer-tool`` subcommand recognizes the\nsome environmental variables which can be shown via the command\n``azulejo dagchainer-tool --help``.\n\n\nInstallation of Binary Dependencies\n-----------------------------------\n``azulejo`` requires `MMseqs <https://github.com/soedinglab/MMseqs2>`_ \nfor homology clustering and `MUSCLE <https://www.drive5.com/muscle/downloads.htm>`_\nfor sequence alignment and initial tree-building.\n``azulejo`` installs binaries into the virtualenv by default, so\nany systemwide installations of these packages will not get clobbered by the install.\nIn particular, ``muscle`` is PGO-optimized, which gives nearly a factor of 2 higher\nperformance than prebuilt binaries.  For fastest installation, We recommand you set\n``MAKEOPTS`` and install all required dependencies via the commands::\n\n        export MAKEOPTS=$(python -c \'import multiprocessing as mp; print(mp.cpu_count())\')\n        azulejo install all\n\nThere are three optional dependencies that can be installed via ``azulejo install`` \nthat are of interest only to a small subset of users who wish to compare against\nother homology clustering and synteny methods.  \n`usearch <https://www.drive5.com/usearch/download.html>`_ \nis a licensed homology clustering program that is free for individual, non-commercial\nuse that can be downloaded and installed by the ``azulejo install usearch``\ncommand after accepting the license terms.  ``azulejo install dagchainer-tool`` gets you\na somewhat crude Bash script that uses BLAST homology clustering followed by \nsynteny calculation via `DAGchainer <https://dagchainer.sourceforge.net>`_.  \n``dagchainer-tool`` will need the dependency of ``perl`` with ``bioperl`` installed.\n``dagchainer_tool`` increases the sequence ID length as part of its processing, so\nif any of your sequence IDS are longer than about 30 characters, they will violate BLAST\'s\nhard limit of 50 characters in sequence ID fields.  In that case you will need\nto install a patched version of BLAST using the command ``azulejo install blast-longids``.\n\nInstallation For Developers\n---------------------------\nIf you plan to develop ``azulejo``, you\'ll need to install\nthe `poetry <https://python-poetry.org>`_ dependency manager.\nIf you haven\'t previously installed ``poetry``, execute the command: ::\n\n    curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python\n\nNext, get the master branch from GitHub ::\n\n\tgit clone https://github.com/joelb123/azulejo.git\n\nChange to the ``azulejo/`` directory and install with poetry: ::\n\n\tpoetry install -v\n\nRun ``azulejo`` with ``poetry``: ::\n\n    poetry run azulejo\n\nUsage\n-----\nInstallation puts a single script called ``azulejo`` in your path.  The usage format is::\n\n    azulejo [GLOBALOPTIONS] COMMAND [COMMANDOPTIONS][ARGS]\n\n\nMaster Input File\n-----------------\n``azulejo`` uses a configuration file in `TOML  <https://github.com/toml-lang/toml>`_\nformat as the master input that associates files with phylogeny.  The format of this file\nis the familiar headings in square brackets followed by configuration values::\n\n    [glycines]\n    rank = "genus"\n    name = "Glycine"\n\n    [glycines.glyso]\n    rank = "species"\n    name = "Glycine soja"\n\n    [glycines.glyso.PI483463]\n    rank = "strain"\n    gff = "glyso.PI483463.gnm1.ann1.3Q3Q.gene_models_main.gff3.gz"\n    fasta = "glyso.PI483463.gnm1.ann1.3Q3Q.protein_primaryTranscript.faa.gz"\n    uri = "https://v1.legumefederation.org/data/index/public/Glycine_soja/PI483463.gnm1.ann1.3Q3Q/"\n    comments = """\n    Glycine soja accession PI 483463 has been identified as being unusually\n    salt-tolerant (Lee et al., 2009)."""\n\n\n* [headings]\n    There can be only one top-level heading, and that will be the name of the\n    resulting output set.  This name will be the name of an output directory that will be\n    created in the current working directory, so this heading (and all subheadings) must\n    obey UNIX filesystem naming rules or an error will result.  Each heading level\n    (indicated by a ".") will result in another taxonomic level and another directory level\n    in the output directory.  Depths do not need to be consistent.\n\n* rank\n    Each level defined must have a ``rank`` defined, and that rank must match one of the\n    taxonomic ranks defined by ``azulejo``, which you can view and test using the\n    ``check-taxonomic-rank`` command.   There are 24 major taxonomic ranks, each of which\n    may be modified by 16 different prefixes for a total of 174 taxonomic levels (some of\n    which are synonoymous).\n\n* name\n    Each level may (and usually should) have a ``name`` defined.  This name is intended\n    to be human-readable with no restrictions on the characters used, but it goes into\n    plot legends in places, so it\'s best to not make it too long. If the name is not specified,\n    it will be taken from the level name enclosed in single quotes (e.g., \'PI483463\' for the\n    example above).\n\n* fasta\n    If the level specifies a genome, it must have a ``fasta`` entry corresponding\n    to the name of the *protein* FASTA file.  In eukaryotes, the FASTA file should be a\n    file of primary (generally longest) protein transcripts, if available, rather than all protein\n    transcripts (i.e., not including splice variants). Sequences will be cleaned of dashes, stops,\n    and other out-of-alphabet characters.  Ambiguous residues at the beginnings and ends of\n    sequences will be trimmed. Zero-length sequences will be discarded, which can result in a\n    smaller number of sequences out.  These files may be compressed, with extensions ``.gz`` or\n    ``.bz2``.\n\n* gff\n    If the level specifies a genome, it must have a ``gff`` entry corresponding\n    to a version 3 Genome Feature File (GFF3) containing ``CDS`` entries with ID values\n    matching those IDs in the FASTA file.  The same compression extensions as for\n    ``fasta`` entries apply.  If the ``SOURCE`` fields in those CDS entries\n    (which contain the names of the DNA fragments such as scaffolds that the CDS came from)\n    contain dot-separated components, those components that are identical across the entire\n    file will be discarded by default.  There is an opportunity later in the process to\n    remap DNA source names to a common dictionary for comparison among chromosomes and\n    plastids.\n\n* uri\n    This optional field may contain a a uniform resource identifier such as\n    ``https://sitename/dir/``.  ``azulejo`` uses `smart-open <https://www.pypi.org/project/smart-open/>`_\n    for doing transparent on-the-fly decompression from a variety of file systems\n    including HTTPS, HDFS, SSH, and SFTP (but not FTP).\n    If this field is not supplied, local file access is assumed with paths relative to\n    the current working directory. The URI will be prepended to ``fasta``\n    and ``gff`` paths, allowing for convenient downloading on-the-fly from sites such as\n    LegumeInfo or GenBank.   Downloads are not cached, so if you intend to run ``azulejo``\n    multiple times on the same input data, you will save time by downloading and uncompressing\n    files to local storage.\n\n* preference\n    This optional field may be used to override the genome preference heuristic\n    that is the fall-thru preference after proxy-gene heuristics have been applied.  This is an integer\n    value, with lower integers getting the highest priority.  Set this value to zero if you\n    know in advance that one of the input genomes is considered the reference genome and,\n    all things being equal, you would prefer to select proxy genes from this genome.  You\n    may also set these preference values later, after the default genome preference (genomes\n    will be preferred in order of the most genes in a single DNA fragment) has already been\n    applied, but before proxy gene selection.\n\n* other info\n    A design goal for ``azulejo`` was to not lose metadata, even if it\n    was not used by ``azulejo`` itself, while keeping metadata out of file names.\n    As an aid in that goal, for each (sub)heading level/output directory, ``azulejo``\n    creates a JSON file named ``node_properties.json`` at each node in the output\n    hierarchy that containing all information from this file as well as other information\n    calculated at ingestion time by ``azulejo``.  You may specify any additional data you would\n    like to pass along (e.g., for later use in a web page) and it will be translated from TOML\n    to JSON and passed along, such as the multi-line ``comments`` field in the example.\n    Examples of useful metadata that may be easier to enter at ingestion time than to\n    garner later include taxon IDs of the level and its parent, common names, URLs of\n    papers describing the genome, and geographic origin of the sample.\n\nA copy of the input file will be saved in the output directory under the name ``input.toml``.\nSee the examples in the ``tests/testdata`` repository directory for examples of input data.\n\nGlobal Options\n--------------\nThe following options are global in scope and, if used must be placed before\n``COMMAND``:\n\n============================= ===========================================\n   -v, --verbose              Log debugging info to stderr.\n   -q, --quiet                Suppress logging to stderr.\n   --no-logfile               Suppress logging to file.\n   -e, --warnings_as_errors   Treat warnings as fatal (for testing).\n============================= ===========================================\n\nCommands\n--------\nA listing of commands is available via ``azulejo --help``.\nThe currently implemented commands are, in the order they will normally be run:\n\n========================= ==================================================\n  install                 Check for/install binary dependencies.\n  ingest                  Marshal protein and genome sequence information.\n  homology                Calculate homology clusters, MSAs, trees.\n  synteny                 Calculate synteny anchors.\n  proxy-genes             Calculate a set of proxy genes from synteny files.\n  parquet-to-tsv          Reads parquet file, writes tsv.\n========================= ==================================================\n\n``azulejo`` stores most intermediate results in the Parquet format with\nextension ``.parq``.  These binary files are compressed and typically can\nbe read more than 30X faster than the tab-separated-value (TSV) files they\ncan be interconverted with.  In addition, Parquet files do not lose metadata\nsuch as binary representation sizes.\n\nEach command has its ``COMMANDOPTIONS``, which may be listed with: ::\n\n    azulejo COMMAND --help\n\nProject Status\n--------------\n+-------------------+-------------+------------+\n| Latest Release    | |pypi|      | |azulejo|  |\n+-------------------+-------------+            +\n| Activity          | |repo|      |            |\n+-------------------+-------------+            +\n| Downloads         | |downloads| |            |\n+-------------------+-------------+            +\n| Download Rate     | |dlrate|    |            |\n+-------------------+-------------+            +\n| License           | |license|   |            |\n+-------------------+-------------+            +\n| Code Grade        | |codacy|    |            |\n+-------------------+-------------+            +\n| Coverage          | |coverage|  |            |\n+-------------------+-------------+            +\n| Travis Build      | |travis|    |            |\n+-------------------+-------------+            +\n| Issues            | |issues|    |            |\n+-------------------+-------------+            +\n| Code Style        | |black|     |            |\n+-------------------+-------------+------------+\n\n\n.. |azulejo| image:: docs/azulejo.jpg\n     :target: https://en.wikipedia.org/wiki/Azulejo\n     :alt: azulejo Definition\n\n.. |black| image:: https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square\n    :target: https://github.com/psf/black\n    :alt: Black is the uncompromising Python code formatter\n\n.. |pypi| image:: https://img.shields.io/pypi/v/azulejo.svg\n    :target: https://pypi.python.org/pypi/azulejo\n    :alt: Python package\n\n.. |repo| image:: https://img.shields.io/github/last-commit/joelb123/azulejo\n    :target: https://github.com/joelb123/azulejo\n    :alt: GitHub repository\n\n.. |license| image:: https://img.shields.io/badge/License-BSD%203--Clause-blue.svg\n    :target: https://github.com/joelb123/azulejo/blob/master/LICENSE\n    :alt: License terms\n\n.. |rtd| image:: https://readthedocs.org/projects/azulejo/badge/?version=latest\n    :target: http://azulejo.readthedocs.io/en/latest/?badge=latest\n    :alt: Documentation Server\n\n.. |travis| image:: https://img.shields.io/travis/joelb123/azulejo.svg\n    :target:  https://travis-ci.org/joelb123/azulejo\n    :alt: Travis CI\n\n.. |codacy| image:: https://api.codacy.com/project/badge/Grade/99549f0ed4e6409e9f5e80a2c4bd806b\n    :target: https://www.codacy.com/app/joelb123/azulejo?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=joelb123/azulejo&amp;utm_campaign=Badge_Grade\n    :alt: Codacy.io grade\n\n.. |coverage| image:: https://codecov.io/gh/joelb123/azulejo/branch/master/graph/badge.svg\n    :target: https://codecov.io/gh/joelb123/azulejo\n    :alt: Codecov.io test coverage\n\n.. |issues| image:: https://img.shields.io/github/issues/LegumeFederation/lorax.svg\n    :target:  https://github.com/joelb123/azulejo/issues\n    :alt: Issues reported\n\n.. |requires| image:: https://requires.io/github/joelb123/azulejo/requirements.svg?branch=master\n     :target: https://requires.io/github/joelb123/azulejo/requirements/?branch=master\n     :alt: Requirements Status\n\n.. |dlrate| image:: https://img.shields.io/pypi/dm/azulejo\n    :target: https://pypistats.org/packages/azulejo\n    :alt: Download stats\n\n.. |downloads| image:: https://pepy.tech/badge/azulejo\n    :target: https://pepy.tech/project/azulejo\n    :alt: Download stats\n',
    'author': 'Joel Berendzen',
    'author_email': 'joel@generisbio.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/joelb123/azulejo',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.7,<4.0',
}


setup(**setup_kwargs)
