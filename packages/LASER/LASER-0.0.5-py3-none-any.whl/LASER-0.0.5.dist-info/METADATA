Metadata-Version: 2.1
Name: LASER
Version: 0.0.5
Summary: A toolkit for large scale distributed training
Home-page: https://github.com/BigBird01/LASER
Author: Pengcheng He
Author-email: penhe@microsoft.com
License: MIT
Keywords: Distributed deep learning
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: pytest
Requires-Dist: regex
Requires-Dist: tqdm
Requires-Dist: ujson
Requires-Dist: psutil
Requires-Dist: torch
Provides-Extra: docs
Requires-Dist: recommonmark ; extra == 'docs'
Requires-Dist: sphinx ; extra == 'docs'
Requires-Dist: sphinx-markdown-tables ; extra == 'docs'
Requires-Dist: sphinx-rtd-theme ; extra == 'docs'

# LASER (a toolkit for Large scAle diStributEd tRaining)
A toolkit for large scale distributed training

With LARSER we succeeded to train [DeBERTa 1.5B](https://github.com/microsoft/DeBERTa) model without model parallelism. The **DeBERTa 1.5B** model is the SOAT model on [GLUE](https://gluebenchmark.com/leaderboard) and [SuperGLUE](https://super.gluebenchmark.com/leaderboard) leaderboard. And it's the first model that surpass **T5 11B model** and human performance on SuperGLUE leaderboard. 

# TODOs
- [ ] Add documentation and usage examples

 git version: 57143200814583410acdd0c5ac0a0f8bab8a1f7e
 date: 2021-02-04 09:55:12.622124

